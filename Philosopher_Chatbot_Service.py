import openai
import streamlit as st
import io
import requests
import re
import deepl
import os 
from dotenv import load_dotenv
import pandas as pd
import numpy as np
# .env íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"  
# OpenAI API í‚¤ ì„¤ì •
os.environ["OPEN_API_KEY"] = st.secrets["OPENAI_API_KEY"]
openai.api_key = os.environ["OPEN_API_KEY"]

#DeepL API í‚¤ ì„¤ì •
translator = deepl.Translator(os.getenv("DeepL_API_KEY"))

# ì‚¬ìš© ê°€ëŠ¥í•œ ì² í•™ìì™€ ëŒ€í™” í”„ë¡¬í”„íŠ¸ ëª©ë¡
philosophers =["ë‹ˆì²´", 'ì¹¸íŠ¸', 'ê³µì', 'ë…¸ì']
#ì¹¸íŠ¸": "In the manner of and with the ideas of Kant, ",
    #"ë§¹ì": "In the manner of and with the ideas of Mencius, ",
    #"ë…¸ì": "In the manner of and with the ideas of Lao Tzu, "

# ë‹µë³€ ê¸¸ì´ ëª©ë¡
len_select = {"ì§§ì€ ë‹µë³€ ğŸ“‘": 100, "ê¸´ ë‹µë³€ ğŸ“œ": 300}

#ì‚¬ìš©ê°€ëŠ¥ ëª¨ë¸ ëª©ë¡
available_models = {
    "GPT-3.5-Turbo": "gpt-3.5-turbo",
    "GPT-4": "gpt-4"
}

#Text Embedding ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
#data_url='https://drive.google.com/uc?id=1wvm_N5-WIfxGrTJ0yI5y91IYMgccyzbh'
#response = requests.get(data_url)
#file_stream = io.BytesIO(response.content)

# pandasë¡œ í”¼í´ íŒŒì¼ ì½ê¸°
df = pd.read_pickle('Embedded text.pickle')
df.reset_index(inplace=True)
df.rename(columns={'index': 'philosopher'}, inplace=True)

#sentence transformer
from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

#ì½”ì‚¬ì¸ ìœ ì‚¬ë„ êµ¬í•˜ê¸°
import torch
import torch.nn.functional as F

def cosine_similarity(tensor1, tensor2):
    # ë‘ í…ì„œ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    return F.cosine_similarity(tensor1, tensor2).item()

def print_similarity(question, philosopher, doc=df):

    # í—ˆìš©ëœ ê²½ì œ ì‚¬ìƒì˜ ëª©ë¡
    allowed_thoughts = {'ë‹ˆì²´','ì¹¸íŠ¸', 'ê³µì', 'ë…¸ì'}

    # ì…ë ¥ëœ ê²½ì œ ì‚¬ìƒì´ í—ˆìš©ëœ ëª©ë¡ì— ì†í•˜ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë°˜í™˜
    if philosopher not in allowed_thoughts:
        raise ValueError("""
        ë¶ˆê°€ëŠ¥í•œ ì² í•™ìì…ë‹ˆë‹¤.
        'ë‹ˆì²´', 'ì¹¸íŠ¸', 'ê³µì', 'ë…¸ì' ì¤‘ ì„ íƒí•˜ì„¸ìš”.
        """)

    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

    # ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•œ ì„ë² ë”©ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    question_embedding = model.encode(question, convert_to_tensor=True).unsqueeze(0)

    # ì‚¬ìƒì— ë§ëŠ” í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìŠ¤íƒí•©ë‹ˆë‹¤.
    doc2 = doc[doc['philosopher'] == philosopher]
    all_embeddings = torch.stack(doc2['embedding'].tolist())

    # ê° ë¬¸ì„œì˜ ì„ë² ë”©ê³¼ ì§ˆë¬¸ì˜ ì„ë² ë”© ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    similarities = F.cosine_similarity(question_embedding, all_embeddings, dim=1)

    # ìœ ì‚¬ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 3ê°œì˜ ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    top_indices = similarities.argsort(descending=True)[:3]

    # ìƒìœ„ 3ê°œì˜ ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    return doc2.iloc[top_indices]['paragraph']

# Streamlit ì•± ì„¤ì •
st.title('ğŸ§”ğŸ“š ì² í•™ìì™€ ëŒ€í™”í•˜ê¸°')

# ì»¬ëŸ¼ ìƒì„±í•˜ì—¬ ë‚˜ë€íˆ ë°°ì—´
col1, col2, col3 = st.columns(3)


# ì²« ë²ˆì§¸ ì»¬ëŸ¼ì— ì² í•™ì ì„ íƒ
# ì‚¬ìš©ì ì„ íƒì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ì„¤ì •
with col1:
    selected_philosopher = st.radio("ğŸ‘¨â€ğŸ« ì² í•™ì ì„ íƒ:", philosophers)
chosen_philosopher=selected_philosopher

# ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì— ë‹µë³€ ê¸¸ì´ ì„ íƒ
# ë‹µë³€ ê¸¸ì´ ì„¤ì • ë²„íŠ¼
# ë‹µë³€ ê¸¸ì´ì— ë”°ë¼ max_tokens ì„¤ì •
with col2:
    selected_len = st.radio("ğŸ—£ï¸ ë‹µë³€ ê¸¸ì´:", list(len_select.keys()))
max_tokens = len_select[selected_len]

# ì„¸ ë²ˆì§¸ ì»¬ëŸ¼ì— ëª¨ë¸ ì„ íƒ
#ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ
with col3:
    selected_model = st.radio("ğŸ¤– ì‚¬ìš©í•  ëª¨ë¸:", list(available_models.keys()))
selected_model_final = available_models[selected_model]


# session_stateì— messages ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    system_message="ë„ˆëŠ” %sì•¼. AIì±—ë´‡ì²˜ëŸ¼ ëŒ€ë‹µí•˜ì§€ë§ê³ , %sì¸ ê²ƒì²˜ëŸ¼ ëŒ€ë‹µí•´ì¤˜"%(chosen_philosopher, chosen_philosopher)
    system_message_eng=translator.translate_text(system_message, target_lang="EN-US").text
    st.session_state.messages = [
        {"role": "system", 
         "content": system_message_eng}
    ]
    
# í¼ ìƒì„±
with st.form(key='message_form'):
    # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ì…ë ¥ ë°›ê¸°
    st.write("ì•ˆë…•í•˜ì„¸ìš”! í™˜ì˜í•©ë‹ˆë‹¤. ì² í•™ìì™€ ëŒ€í™”ë¥¼ ì‹œì‘í•´ ë³´ì„¸ìš”!")
    user_message = st.text_input("ì² í•™ìì—ê²Œ ê³ ë¯¼ì„ ë§í•´ë³´ì„¸ìš”: ")
    
    # í¼ ì œì¶œ ë²„íŠ¼ ì¶”ê°€
    submit_button = st.form_submit_button(label='ì „ì†¡')
    
def create_eng_chat_message(philosopher, question, input_text, max_tokens):
    user_prompt="""
        question: %s \n 
        Below texts are written by %s \n
            |1. {%s}
            2. {%s}
            3. {%s}|\n
        Answer about question above, based on the texts above and %s's ideas, in the manner of %s, in %d words.
        """%(question, philosopher, input_text.iloc[0], input_text.iloc[1], input_text.iloc[2], philosopher, philosopher, max_tokens)
    st.session_state.messages.append({"role": "user", 
                                      "content": user_prompt+'@@@'+question})

    # OpenAI GPT-3.5-turboë¥¼ ì‚¬ìš©í•´ ì‘ë‹µ ìƒì„±
    response = openai.chat.completions.create(
            model=selected_model_final,
            messages=st.session_state.messages, 
        )
    answer = translator.translate_text(response.choices[0].message.content, target_lang='KO').text
    return answer

def create_ko_chat_message(philosopher, question, input_text, max_tokens):
    user_prompt="""
        ìƒë‹´ ë‚´ìš©: %s \n
        ì•„ë˜ì—ëŠ” %sì˜ ì €ì„œì˜ êµ¬ì ˆì´ì•¼. \n
            |1. {%s}
            2. {%s}
            3. {%s}|\n
        ìœ„ ìƒë‹´ ë‚´ìš©ì— ëŒ€í•´, ìœ„ êµ¬ì ˆê³¼ %sì˜ ì‚¬ìƒì„ ë°”íƒ•ìœ¼ë¡œ %d ë‹¨ì–´ ì´ë‚´ë¡œ, %sì˜ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´ì„œ ë§ˆì¹˜ %sì¸ ê²ƒì²˜ëŸ¼ ì¹œì ˆí•˜ê²Œ ìƒë‹´í•´ì¤˜.
        """%(question, philosopher, input_text.iloc[0], input_text.iloc[1], input_text.iloc[2], 
             philosopher, max_tokens, philosopher, philosopher)
    user_prompt_eng=translator.translate_text(user_prompt, target_lang="EN-US").text
    st.session_state.messages.append({"role": "user", 
                                      "content": user_prompt_eng+'@@@'+question})

    # OpenAI GPT-3.5-turboë¥¼ ì‚¬ìš©í•´ ì‘ë‹µ ìƒì„±
    response = openai.chat.completions.create(
            model=selected_model_final,
            messages=st.session_state.messages, 
        )
    answer = translator.translate_text(response.choices[0].message.content, target_lang='KO').text
    return answer

if submit_button and user_message:
    #user_message_en=translator.translate_text(user_message, target_lang="EN-US").text
    input_question= user_message if chosen_philosopher in ['ê³µì', 'ë…¸ì'] else translator.translate_text(user_message, target_lang='EN-US').text
    input_text=print_similarity(input_question, chosen_philosopher)
    philosopher_eng = chosen_philosopher if chosen_philosopher in ['ê³µì', 'ë…¸ì'] else translator.translate_text(chosen_philosopher, target_lang='EN-US').text
    question_text = input_question if chosen_philosopher in ['ê³µì', 'ë…¸ì'] else translator.translate_text(input_question, target_lang='EN-US').text

    if chosen_philosopher not in ['ê³µì', 'ë…¸ì']:
        answer = create_eng_chat_message(philosopher_eng, question_text, input_text, max_tokens)
    else:
        answer = create_ko_chat_message(chosen_philosopher, input_question, input_text, max_tokens)
   
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    st.session_state.messages.append({"role": "assistant", "content": answer+'@@@'+chosen_philosopher})

# ëŒ€í™” ë¡œê·¸ ë° ìƒíƒœ ì´ˆê¸°í™” ë²„íŠ¼ë“¤
if st.button("ëŒ€í™” ë‹¤ì‹œ ì‹œì‘í•˜ê¸°"):
    st.session_state.messages = []
    #st.session_state.messages = [
        #{"role": "system", 
         #"content": "You are %s. Do not act like a chatbot and just be %s himself" % (selected_prompt.split(' ')[9].replace(',','') , selected_prompt.split(' ')[9].replace(',',''))}
    #]

st.subheader("ğŸ“ ëŒ€í™” ë¡œê·¸")
st.write("_________________________________________________________________________________________________________")
for message in st.session_state.messages:
    if message["role"] == "user":
        input_message = message['content'].split('@@@')[1]
        st.write("ğŸ™‹â€â™‚ë‚˜:")
        st.write(input_message)
        st.write(message['content'])
        st.write("_________________________________________________________________________________________________________")
        st.write("ì°¸ê³  ì €ì„œ êµ¬ì ˆ: " )
        parts = message['content'].split('|')
        for part in parts[1:-1]:
            part=part.replace('{', ' ')
            part=part.replace('}', ' ')
            part_ko=translator.translate_text(part, target_lang='KO').text
            formatted_text = re.sub(r"(\d+\.)", r"\n\1", part_ko)
            st.write(formatted_text)
            st.write('\n hi \n')
    elif message["role"] == "assistant":
        gpt_answer = message['content'].split('@@@')[0]
        st.write("ğŸ§” %s: "%(message['content'].split('@@@')[1]))
        st.write(f"{gpt_answer}")
        st.write("_________________________________________________________________________________________________________")
            
